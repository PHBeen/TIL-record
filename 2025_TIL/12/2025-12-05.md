# TIL Template
날짜: 2025-12-05

## 스크럼
- 학습 목표 1 : CogVideoX 다시 공부하기..


## 새로 배운 내용
### 주제 1: CogVideoX 다시 공부하기.
- **텍스트 임베딩**: 

    | 단계                         | 무슨 과정인가                  | 출력 텐서             | 내부 연산                        |
    | -------------------------- | ------------------------ | ----------------- | ---------------------------- |
    | **1. 토큰화(Tokenization)**   | 문장을 정수 ID로 변환            | `[B, L]` (L ≤ 77) | BPE 토크나이저                    |
    | **2. Token Embedding**     | 각 토큰 ID를 벡터로 변환          | `[B, L, D]`       | Lookup table (Embedding)     |
    | **3. Position Embedding**  | 토큰 위치 정보 추가              | `[B, L, D]`       | Learnable position embedding |
    | **4. Transformer Encoder** | 문장의 의미 정제                | `[B, L, D]`       | Self-Attention + FFN         |
    | **5. Projection Layer**    | CogVideoX hidden dim에 맞춤 | `[B, L, D_model]` | Linear projection            |

- **이미지 임베딩**:

    | 단계                       | 무슨 과정인가                      | 출력 텐서                         | 내부 연산                 |
    | ------------------------ | ---------------------------- | ----------------------------- | --------------------- |
    | **1. 이미지/프레임 입력**        | RGB 이미지/프레임 준비               | `[B, F, 3, H, W]`         | 없음                    |
    | **2. 3D VAE Encoder**    | 비디오/이미지를 latent로 압축          | `[B, F, C, H', W']`           | Conv3D + Downsampling |
    | **3. Patch 분할**          | latent를 여러 패치로 자름          | `[B, N_patches, patch_vec]`   | 패치 단위로 slice          |
    | **4. Flatten**           | 패치를 1D 벡터로 변환                | `[B, N_patches, C * ph * pw]` | reshape/flatten       |
    | **5. Linear Projection** | Transformer의 hidden dim으로 맞춤 | `[B, N_tokens, D_model]`      | Linear layer          |

- **transformer 입력**:

    | 구성                          | 출력 텐서                            | 설명                  |
    | --------------------------- | -------------------------------- | ------------------- |
    | **텍스트 토큰 시퀀스**              | `[B, L_text, D_model]`           | 문장 정보               |
    | **비디오 latent 토큰 시퀀스**       | `[B, N_video, D_model]`          | 영상 구조·모션 정보         |
    | **Concat 후 Transformer 입력** | `[B, L_text + N_video, D_model]` | DiT가 처리하는 최종 토큰 시퀀스 |



## 오늘의 도전 과제와 해결 방법
- 최적화 전략을 이해하기 위해.. CogVideoX의 내부를 좀더 완벽히 이해해야겠다.


## 오늘의 회고
-  
