# TIL Template
날짜: 2025-11-28

## 스크럼
- 학습 목표 1 : Onnx 추론 최적화 적용 글 1편 업로드(2편으로 나누어 업로드 진행하기)
- 학습 목표 2 : 품앗이 프로젝트에 최적화 방향 고안하기.


## 새로 배운 내용
### 주제 1: Onnx 추론 최적화 적용 글 업로드(2편으로 나누어 업로드 진행하기).
- **DistilBERT의 모델 구조**: 
    - 기존 BERT 모델의 Encoder layer에서 짝수 layer만 가져옴 12layers -> 6layers로 layer수 감소(경량화)
- **파인튜닝 전, 후의 layer distribution 비교**: 
    <img width="800" height="400" alt="image" src="https://github.com/user-attachments/assets/0851c87c-9ec2-46fa-99cd-3b2c4bd5a6ff" />
- **파인튜닝까지 내용을 업로드 완료**: 아래 링크를 참조



### 주제 2: 품앗이 프로젝트에 최적화 방향 고안.
- **댓글기능**: 
    - 현재 기능 평가: AI 댓글기능은 빠른 응답을 요구하지 않고, 부하가 많은 기능이 아니지만, CPU 환경에서 동작하는 특성상 완성도를 높이기 위해 최적화 진행 필요.
    - 적용 가능한 최적화 방법: CPU환경 서빙 -> ONNX 최적화 + ONNX Runtime으로 모델 추론속도 최적화.
- **배지기능**: 
    - 현재 기능 평가: 현재 GCS캐싱기능을 통해, 20s-> 2s로 응답시간이 감소하였으나 확장성을 위해 모델 자체의 최적화는 필요하다. Stable-Diffusion은 UNet기반 추론을 진행하므로 모델 자체를 최적화를 진행하기 쉽지 않다. 
    - 적용 가능한 최적화 방법: 모델을 Stable-Diffusion -> FLUX로 변경(transformer기반모델)하여 PyTorch기반의 최적화 진행.


## 오늘의 도전 과제와 해결 방법
- 직접 파인튜닝 전, 후 과정을 heatmap을 통해 확인해본다.


## 오늘의 회고
- 글을 올리는 과정에서 직접 아키텍처를 이미지로 그리는 것 보다 코드로 모델 layer를 출력하는게 효율적이라는 사실을 알았다.
- 그림에 대한 설명을 할때에는 목록 형식으로 정리하는 편이 가독성을 높일 수 있음을 알았다.


## 참고 자료 및 링크
- [데이터 수집, 파인튜닝 과정](https://hyo6490.tistory.com/7) : 모델의 성능(정확도 향상)측면에서 블로그 글 업로드
