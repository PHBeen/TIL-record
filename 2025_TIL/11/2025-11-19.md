# TIL Template
날짜: 2025-11-19

## 스크럼
- 학습 목표 1 : transformer 모델의 등장 배경 확인하기


## 새로 배운 내용
### 주제 1: transformer 모델의 등장 배경 확인하기
- **transformer 이전 모델에 대한 고찰** : RNN의 입력 방식은 순차적입력인 반면, transformer의 입력 방식은 임베딩 + 위치 인코딩으로 기존 모델이 가지는 긴 입력에 대한 한계를 해결하고자 하였다.


## 오늘의 회고
- Sequence2Sequence 모델의 한계를 이해하고, 인코더+ 디코더 모델의 구조를 이해하여 현재 GPT 구조를 파헤칠 수 있다.
